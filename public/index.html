<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Dr. Ahmed Moustafa — Associate Professor, Responsible AI Lab</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="container">
    <header class="site-header">
              <img src="Ahmed-Mostafa-photo.jpg" alt="Dr. Ahmed Moustafa" class="profile-photo">
      <h1>Dr. Ahmed Moustafa</h1>
      <p class="subtitle">Associate Professor in AI · Head, Responsible AI Lab (RAIL)</p>
      <p class="links">
        <a href="mailto:ahmed.moustafa@dmu.ac.uk">ahmed.moustafa@dmu.ac.uk</a>
      </p>
    </header>

    <main>
      <section id="about">
        <h2>About</h2>
        <p>I am an Associate Professor working in artificial intelligence and the head of the Responsible AI Lab (RAIL). My work focuses on building reliable, fair, and interpretable AI systems.</p>
        <p class="bio">Brief bio: I lead the Responsible AI Lab at De Montfort University (DMU), where I supervise research on fairness, interpretability, and trustworthy machine learning. I teach undergraduate and postgraduate courses in AI and mentor PhD students working on responsible and reliable AI systems.</p>
      </section>

      <section id="research">
        <h2>Research</h2>
        <p>Research interests include Responsible AI, fairness, interpretability, and trustworthy ML systems. See my publications and projects (links to be added).</p>
      </section>

          <section id="phd-projects">
      <h2>PhD Projects</h2>
                  <p>I am currently accepting PhD students. Interested students should contact <a href="mailto:ahmed.moustafa@dmu.ac.uk">ahmed.moustafa@dmu.ac.uk</a>.</p>
      <h3>(1) Heterogeneous Data-Aware Federated Learning for Medical AI</h3>
      <p>This project develops strategies to handle non-independent and identically distributed (non-iiD) data in federated learning for healthcare. Current federated learning algorithms assume iiD datasets, which limits their effectiveness with real-world heterogeneous healthcare data sources. The research aims to enable privacy-preserving machine learning on diverse medical datasets.</p>    </section>

            <h3>(2) Promoting Fairness in AutoML Systems</h3>
      <p>This project develops dynamic strategies to mitigate unfairness in AutoML systems by addressing societal biases in training data and development decisions. The research focuses on optimizing accuracy-fairness trade-offs to determine when and how to apply fairness interventions across different ML models in automated machine learning pipelines.</p>

      <h3>(3) Safe and Interpretable Reinforcement Learning for Personalized Healthcare</h3>
      <p>This project develops Safe RL frameworks with interpretable models (e.g., PIRL) and human-in-the-loop systems for personalized treatment optimization and drug discovery. By integrating multi-objective optimization, it addresses data sparsity, black-box decision-making, and clinical bias to enable trustworthy AI-driven healthcare solutions.</p>

      <h3>(4) Multi-Agent Reinforcement Learning for Resilient Supply Chains</h3>
      <p>This project develops scalable MARL systems to optimize supply chain resilience against disruptions and market volatility. By integrating Multi-Objective RL to balance cost, availability, and robustness, it addresses coordination challenges, non-stationarity, and credit assignment while improving sample efficiency for large-scale networks.</p>

      <h3>(5) Human-in-the-Loop Reinforcement Learning for Proactive Cybersecurity Defence</h3>
      <p>This project combines AI-driven threat detection with human expertise through Human-in-the-Loop RL for proactive, accountable cyber defense. The system enables continuous learning from evolving attacks while ensuring transparency, bias mitigation through human oversight, and Safe RL principles to prevent harmful autonomous actions in cybersecurity operations.</p>

      <section id="contact">
        <h2>Contact</h2>
        <p>For collaborations or inquiries, email <a href="mailto:ahmed.moustafa@dmu.ac.uk">ahmed.moustafa@dmu.ac.uk</a>.</p>
      </section>
    </main>

    <footer>
      <p>&copy; 2025 Dr. Ahmed Moustafa</p>
    </footer>
  </div>
</body>
</html>
